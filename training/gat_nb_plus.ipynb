{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b67afbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/infolab/sarvam/env_sd/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "sys.path.insert(1, os.getenv(\"PROJECT_ROOT\"))\n",
    "os.environ['HF_HOME'] = os.getenv(\"HF_CACHE\")\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import dgl\n",
    "from dgl import heterograph\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "\n",
    "# Load SciBERT model\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\", local_files_only=True)\n",
    "model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\", local_files_only=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bd4e717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11528/11528 [00:00<00:00, 40314.18it/s]\n",
      "100%|██████████| 1500/1500 [00:00<00:00, 75110.20it/s]\n",
      "11528it [01:26, 133.05it/s]\n",
      "1500it [00:10, 139.35it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_scibert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "    return cls_embedding  # shape: (1, hidden_size)\n",
    "\n",
    "\n",
    "paper_records = pickle.load(open('data/teacher_graph/records/paper_records.pkl', \"rb\"))\n",
    "author_records = pickle.load(open('data/teacher_graph/records/author_records.pkl', \"rb\"))\n",
    "fields_of_study = set()\n",
    "affiliations = set()\n",
    "\n",
    "all_ids = set(paper_records.keys())\n",
    "student_paper_ids = pickle.load(open('data/teacher_graph/paper_ids.pkl', \"rb\"))\n",
    "eval_ids = pickle.load(open('data/teacher_graph/eval_ids.pickle', \"rb\"))\n",
    "test_ids = pickle.load(open('data/teacher_graph/test_ids.pickle', \"rb\"))\n",
    "extra_train_ids = pickle.load(open('data/teacher_graph/extra_train_ids.pickle', \"rb\"))\n",
    "\n",
    "# create a combined set of student paper ids and extra train ids\n",
    "train_ids = set(student_paper_ids).union(extra_train_ids)\n",
    "\n",
    "# combined_ids = set(train_ids).union(eval_ids)\n",
    "\n",
    "train_ids_nums = {i:idx for idx, i in enumerate(train_ids)}\n",
    "train_nodes = [v for k,v in train_ids_nums.items()]\n",
    "\n",
    "eval_ids_nums = {i:idx for idx, i in enumerate(eval_ids)}\n",
    "eval_nodes = [v for k,v in eval_ids_nums.items()]\n",
    "\n",
    "# for author_id, author in tqdm(author_records.items()):\n",
    "#     affiliations.update(author['affiliations'])\n",
    "\n",
    "# for s2_id, paper in tqdm(paper_records.items()):\n",
    "#     fields_of_study.update(paper['field_ids'])\n",
    "\n",
    "\n",
    "\n",
    "train_graph = nx.DiGraph()\n",
    "\n",
    "# add nodes for all papers\n",
    "train_graph.add_nodes_from(train_nodes)\n",
    "\n",
    "# add edges for all papers\n",
    "edges = []\n",
    "\n",
    "for s2_id in tqdm(train_ids):\n",
    "    paper = paper_records[s2_id]\n",
    "    for ref_id in paper['reference_ids']:\n",
    "        if ref_id in train_ids:\n",
    "            if ref_id == None:\n",
    "                continue\n",
    "            edges.append((train_ids_nums[s2_id], train_ids_nums[ref_id])) # paper -> reference\n",
    "   \n",
    "train_graph.add_edges_from(edges)\n",
    "train_feats = torch.zeros((len(train_ids), 768))\n",
    "\n",
    "\n",
    "eval_edges = []\n",
    "for s2_id in tqdm(eval_ids):\n",
    "    paper = paper_records[s2_id]\n",
    "    for ref_id in paper['reference_ids']:\n",
    "        if ref_id in train_ids:\n",
    "            if ref_id == None:\n",
    "                continue\n",
    "            eval_edges.append((eval_ids_nums[s2_id], train_ids_nums[ref_id])) # paper -> reference\n",
    "\n",
    "\n",
    "# Compute and assign SciBERT embeddings for paper nodes\n",
    "for local_idx, global_id in tqdm(enumerate(train_ids)):\n",
    "    pdata = paper_records[global_id]\n",
    "    if pdata['abstract'] is None:\n",
    "        abstract = \"\"\n",
    "    else:\n",
    "        abstract = pdata['abstract']\n",
    "    text = pdata['title'] + \"\\n\" + abstract + \"\\n\"\n",
    "    text += f\"This paper was published in {pdata['venue']} in {pdata['year']}. It has {len(pdata[\"author_ids\"])} authors and {pdata['referenceCount']} references. It has {pdata[\"citationCount\"]} citations and {pdata[\"influentialCitationCount\"]} influential citations.\"\n",
    "    emb = get_scibert_embedding(text)\n",
    "    train_feats[local_idx] = emb\n",
    "\n",
    "# 1. Prepare eval node SciBERT embeddings (once)\n",
    "eval_feats = torch.zeros(len(eval_ids), 768)\n",
    "for local_idx, global_id in tqdm(enumerate(eval_ids)):\n",
    "    pdata = paper_records[global_id]\n",
    "    if pdata['abstract'] is None:\n",
    "        abstract = \"\"\n",
    "    else:\n",
    "        abstract = pdata['abstract']\n",
    "    text = pdata['title'] + \"\\n\" + abstract + \"\\n\"\n",
    "    emb = get_scibert_embedding(text)\n",
    "    eval_feats[local_idx] = emb\n",
    "\n",
    "# train the model using the graph attention network\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "train_feats = train_feats.to(device)\n",
    "eval_feats = eval_feats.to(device)\n",
    "\n",
    "combined_feats = torch.cat((train_feats, eval_feats), dim=0)\n",
    "combined_feats = combined_feats.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "572e72a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_graph = nx.DiGraph()\n",
    "# add nodes for all papers\n",
    "eval_graph.add_nodes_from(eval_nodes)\n",
    "# add edges for all papers\n",
    "eval_graph.add_edges_from([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f0c5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163cee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(pos_score, neg_score):\n",
    "    pos_loss = -F.logsigmoid(pos_score).mean()\n",
    "    neg_loss = -F.logsigmoid(-neg_score).mean()\n",
    "    return pos_loss + neg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f67e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:05<00:00, 11.86it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.67it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 15.52it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.57it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Average Loss: 1.9430\n",
      "Recall@10: 0.0012 | Recall@20: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 20.44it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.86it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.79it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.12it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 20.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Average Loss: 1.0357\n",
      "Recall@10: 0.0016 | Recall@20: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 16.44it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.79it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.82it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.38it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 12.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Average Loss: 1.0149\n",
      "Recall@10: 0.0036 | Recall@20: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:05<00:00, 12.15it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 15.51it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 15.18it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 15.89it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Average Loss: 1.0028\n",
      "Recall@10: 0.0041 | Recall@20: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 20.65it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.06it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.17it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.26it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 20.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Average Loss: 0.9905\n",
      "Recall@10: 0.0050 | Recall@20: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 18.40it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.83it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.86it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.08it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 12.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Average Loss: 0.9835\n",
      "Recall@10: 0.0074 | Recall@20: 0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 14.75it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 13.50it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 15.46it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.32it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 20.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Average Loss: 0.9695\n",
      "Recall@10: 0.0109 | Recall@20: 0.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 15.81it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.25it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.68it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 20.96it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Average Loss: 0.9668\n",
      "Recall@10: 0.0101 | Recall@20: 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 19.16it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.62it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.14it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.38it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Average Loss: 0.9558\n",
      "Recall@10: 0.0163 | Recall@20: 0.0299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 13.29it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.38it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.18it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.48it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Average Loss: 0.9526\n",
      "Recall@10: 0.0498 | Recall@20: 0.0801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:05<00:00, 10.77it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 15.42it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.63it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 20.14it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Average Loss: 0.9458\n",
      "Recall@10: 0.0539 | Recall@20: 0.0825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 19.90it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 11.39it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 11.84it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.12it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Average Loss: 0.9389\n",
      "Recall@10: 0.0470 | Recall@20: 0.0722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 12.99it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 15.39it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.70it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 15.35it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Average Loss: 0.9306\n",
      "Recall@10: 0.0385 | Recall@20: 0.0581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 17.01it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.49it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.39it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.90it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Average Loss: 0.9325\n",
      "Recall@10: 0.0536 | Recall@20: 0.0828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 20.15it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 13.49it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.94it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 15.01it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 12.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Average Loss: 0.9239\n",
      "Recall@10: 0.0589 | Recall@20: 0.0876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 14.63it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 15.45it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.76it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.57it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Average Loss: 0.9250\n",
      "Recall@10: 0.0655 | Recall@20: 0.0931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 17.54it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 20.19it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.88it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 15.78it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Average Loss: 0.9223\n",
      "Recall@10: 0.0547 | Recall@20: 0.0774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 12.65it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 11.99it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 13.32it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 12.84it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 12.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Average Loss: 0.9171\n",
      "Recall@10: 0.0522 | Recall@20: 0.0757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 19.56it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 11.00it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.77it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.31it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Average Loss: 0.9106\n",
      "Recall@10: 0.0664 | Recall@20: 0.0991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 18.47it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.87it/s]\n",
      "100%|██████████| 63/63 [00:06<00:00,  9.92it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 12.27it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Average Loss: 0.9124\n",
      "Recall@10: 0.0671 | Recall@20: 0.0979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 15.54it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.29it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 11.08it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 12.94it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Average Loss: 0.9042\n",
      "Recall@10: 0.0585 | Recall@20: 0.0876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 15.45it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.19it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.66it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 12.61it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Average Loss: 0.9047\n",
      "Recall@10: 0.0541 | Recall@20: 0.0797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:05<00:00, 11.70it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 13.92it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.08it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 20.68it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Average Loss: 0.9044\n",
      "Recall@10: 0.0732 | Recall@20: 0.1058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 14.72it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.36it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.78it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.74it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Average Loss: 0.9040\n",
      "Recall@10: 0.0532 | Recall@20: 0.0841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 15.26it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 12.93it/s]\n",
      "100%|██████████| 63/63 [00:06<00:00, 10.44it/s]\n",
      "100%|██████████| 63/63 [00:06<00:00,  9.96it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Average Loss: 0.8971\n",
      "Recall@10: 0.0544 | Recall@20: 0.0782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 16.24it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.05it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.26it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.96it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Average Loss: 0.8952\n",
      "Recall@10: 0.0673 | Recall@20: 0.0984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 19.41it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.14it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.64it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 13.31it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Average Loss: 0.8944\n",
      "Recall@10: 0.0552 | Recall@20: 0.0782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 12.86it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 13.80it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 11.82it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 13.92it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Average Loss: 0.8942\n",
      "Recall@10: 0.0692 | Recall@20: 0.1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:05<00:00, 11.38it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.49it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.79it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.91it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Average Loss: 0.8934\n",
      "Recall@10: 0.0607 | Recall@20: 0.0852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 19.19it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 12.31it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 12.79it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.46it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Average Loss: 0.8879\n",
      "Recall@10: 0.0601 | Recall@20: 0.0859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 13.29it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.48it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.85it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.63it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Average Loss: 0.8878\n",
      "Recall@10: 0.0555 | Recall@20: 0.0824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:05<00:00, 10.60it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 15.95it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.36it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.61it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Average Loss: 0.8870\n",
      "Recall@10: 0.0637 | Recall@20: 0.0895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 20.05it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.25it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 12.13it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 10.98it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 13.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Average Loss: 0.8855\n",
      "Recall@10: 0.0656 | Recall@20: 0.0907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 12.92it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.47it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 13.82it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.00it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Average Loss: 0.8849\n",
      "Recall@10: 0.0519 | Recall@20: 0.0757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 17.11it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.67it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.98it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 18.77it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Average Loss: 0.8793\n",
      "Recall@10: 0.0586 | Recall@20: 0.0826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:05<00:00, 12.04it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 15.58it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 11.30it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 11.92it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Average Loss: 0.8804\n",
      "Recall@10: 0.0658 | Recall@20: 0.0924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 16.51it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 12.80it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 13.89it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.54it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Average Loss: 0.8807\n",
      "Recall@10: 0.0712 | Recall@20: 0.1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 15.49it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 12.51it/s]\n",
      "100%|██████████| 63/63 [00:05<00:00, 11.58it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 15.72it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Average Loss: 0.8802\n",
      "Recall@10: 0.0639 | Recall@20: 0.0869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 13.48it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 15.30it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.85it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.88it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Average Loss: 0.8790\n",
      "Recall@10: 0.0685 | Recall@20: 0.0965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 16.22it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 20.52it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 20.27it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.52it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Average Loss: 0.8769\n",
      "Recall@10: 0.0552 | Recall@20: 0.0772\n"
     ]
    }
   ],
   "source": [
    "def calculate_recall_at_k_fixed(eval_ids, predicted_indices, k):\n",
    "    \"\"\"\n",
    "    Calculate recall@k for evaluation nodes, mapping indices back to global IDs.\n",
    "    Args:\n",
    "        eval_ids: List of evaluation node IDs (global IDs)\n",
    "        predicted_indices: Tensor of predicted train node indices for each eval node\n",
    "        k: Number of top predictions to consider\n",
    "        train_ids_list: List of train node IDs (global IDs) in the same order as used in the model\n",
    "    Returns:\n",
    "        recall: Recall@k value\n",
    "    \"\"\"\n",
    "    relevant_count = 0\n",
    "    total_relevant = 0\n",
    "    \n",
    "    for eval_idx, eval_id in enumerate(eval_ids):\n",
    "        paper = paper_records[eval_id]\n",
    "        true_references = set(ref for ref in paper['reference_ids'] if ref in train_ids)\n",
    "        true_references = set([train_ids_nums[i] for i in true_references])\n",
    "        total_relevant += len(true_references)\n",
    "        \n",
    "        # Map predicted indices back to global IDs\n",
    "        predicted_refs = predicted_indices[eval_idx, :k].cpu().tolist()\n",
    "        # predicted_refs = set(train_ids_list[idx] for idx in pred_indices)\n",
    "        \n",
    "        relevant_count += len(true_references.intersection(predicted_refs))\n",
    "    \n",
    "    if total_relevant == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return relevant_count / total_relevant\n",
    "\n",
    "in_dim = train_feats.shape[1]\n",
    "hidden_dim = 128\n",
    "num_heads = 4\n",
    "\n",
    "class DotLinkPredictor(nn.Module):\n",
    "    def forward(self, h, src_idx, dst_idx):\n",
    "        return (h[src_idx] * h[dst_idx]).sum(dim=-1)\n",
    "    \n",
    "    # Alternative implementation that avoids the in-place operation issue\n",
    "class GATLinkPredictorFixed(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, num_heads):\n",
    "        super(GATLinkPredictorFixed, self).__init__()\n",
    "        self.gat1 = GATConv(in_dim, hidden_dim, num_heads)\n",
    "        self.gat2 = GATConv(hidden_dim * num_heads, hidden_dim, 1)\n",
    "        \n",
    "    # def encode_without_graph(self, features):\n",
    "    #     \"\"\"Process nodes without graph structure (for evaluation)\"\"\"\n",
    "    #     h = self.gat1(features, edge_index=None)\n",
    "    #     h = F.elu(h.flatten(1))\n",
    "    #     h = self.gat2(h, edge_index=None).squeeze(1)\n",
    "    #     return h\n",
    "    \n",
    "    def forward(self, g, features):\n",
    "        # For NetworkX graph compatibility\n",
    "        if isinstance(g, nx.DiGraph):\n",
    "            edge_index = torch.tensor(list(g.edges())).t().to(device)\n",
    "            # create empty tensor of size (2, num_edges)\n",
    "            if edge_index.shape[0] == 0:\n",
    "                edge_index = torch.zeros((2, len(eval_edges)), dtype=torch.long).to(device)\n",
    "            h = self.gat1(features, edge_index)\n",
    "            h = F.elu(h.flatten(1))\n",
    "            h = self.gat2(h, edge_index).squeeze(1)\n",
    "        else:\n",
    "            # Original implementation for other graph types\n",
    "            h = self.gat1(g, features)\n",
    "            h = F.elu(h.flatten(1))\n",
    "            h = self.gat2(g, h).squeeze(1)\n",
    "        return h\n",
    "\n",
    "# Fixed training loop\n",
    "model_fixed = GATLinkPredictorFixed(in_dim, hidden_dim, num_heads).to(device)\n",
    "predictor = DotLinkPredictor()\n",
    "optimizer = torch.optim.Adam(list(model_fixed.parameters()) + list(predictor.parameters()), lr=1e-3)\n",
    "\n",
    "for epoch in range(40):\n",
    "    model_fixed.train()\n",
    "    \n",
    "    # Get edges for training\n",
    "    edge_list = list(train_graph.edges())\n",
    "    src, dst = zip(*edge_list)\n",
    "    src = torch.tensor(src, dtype=torch.long).to(device)\n",
    "    dst = torch.tensor(dst, dtype=torch.long).to(device)\n",
    "    n_edges = src.shape[0]\n",
    "    \n",
    "    # Process all edges in a single batch with multiple epochs\n",
    "    # This prevents in-place modification issues\n",
    "    batch_losses = []\n",
    "    \n",
    "    # Process in smaller sub-epochs\n",
    "    for sub_epoch in range(5):  # 5 sub-epochs per epoch\n",
    "        perm = torch.randperm(n_edges)\n",
    "        \n",
    "        for i in tqdm(range(0, n_edges, 1024)):\n",
    "            # Get embeddings for all nodes\n",
    "            h = model_fixed(train_graph, train_feats)\n",
    "            \n",
    "            batch_src = src[perm[i:i+1024]]\n",
    "            batch_dst = dst[perm[i:i+1024]]\n",
    "            \n",
    "            # Negative sampling\n",
    "            neg_dst = torch.randint(0, h.shape[0], batch_dst.shape, dtype=torch.long).to(device)\n",
    "            \n",
    "            pos_score = predictor(h, batch_src, batch_dst)\n",
    "            neg_score = predictor(h, batch_src, neg_dst)\n",
    "            \n",
    "            loss = compute_loss(pos_score, neg_score)\n",
    "            batch_losses.append(loss.item())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()  # No retain_graph needed\n",
    "            optimizer.step()\n",
    "    \n",
    "    avg_loss = sum(batch_losses) / len(batch_losses)\n",
    "    print(f\"Epoch {epoch} | Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Evaluation\n",
    "    model_fixed.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get train node embeddings\n",
    "        train_embs = model_fixed(train_graph, train_feats)\n",
    "        \n",
    "        # Get eval node embeddings without graph structure\n",
    "        eval_embs = model_fixed(eval_graph, eval_feats)\n",
    "        \n",
    "        # Compute similarity scores\n",
    "        scores = torch.matmul(eval_embs, train_embs.T)\n",
    "        \n",
    "        # Get top-k predictions\n",
    "        topk = torch.topk(scores, k=20, dim=1)\n",
    "        predicted_indices = topk.indices\n",
    "        \n",
    "        # Calculate recall@k with the fixed function\n",
    "        recall_at_10 = calculate_recall_at_k_fixed(eval_ids, predicted_indices, 10)\n",
    "        recall_at_20 = calculate_recall_at_k_fixed(eval_ids, predicted_indices, 20)\n",
    "        \n",
    "        print(f\"Recall@10: {recall_at_10:.4f} | Recall@20: {recall_at_20:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab96407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_fixed.state_dict(), 'model/gat_model_plus.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c14a819b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3151549/1001121453.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model2.load_state_dict(torch.load('model/gat_model_plus.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GATLinkPredictorFixed(\n",
       "  (gat1): GATConv(768, 128, heads=4)\n",
       "  (gat2): GATConv(512, 128, heads=1)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = GATLinkPredictorFixed(in_dim, hidden_dim, num_heads)\n",
    "model2.load_state_dict(torch.load('model/gat_model_plus.pt'))\n",
    "model2.to(device)  # move to GPU if needed\n",
    "model2.eval()      # set to evaluation mode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
